# ComMAND: A Combined Method for Author Name Disambiguation

This work presents a framework with ComMAND for Author Name Disambiguation (AND). It combines transfer learning using SciBERT-based embeddings, constructing a heterogeneous graph, and learning with Graph Convolutional Networks (GCN) and Graph-enhanced Hierarchical Agglomerative Clustering (GHAC) clustering. The framework is accessible via a Graphical User Interface (GUI).

## ğŸ–¼ï¸ Graphical Interface

The framework includes a graphical interface that allows users to run the full pipeline without coding. Users can select features, run preprocessing, extract embeddings, create graphs, and apply GCN and GHAC models step by step.

![GUI](image.png)


## Project Structure

```
â”œâ”€â”€ data_process/
â”‚   â”œâ”€â”€ pre_processing.py
â”‚   â””â”€â”€ pre_process_ghac.py
â”œâ”€â”€ datasets/                    # Input and processed data
â”œâ”€â”€ gcn/
â”‚   â””â”€â”€ embedding_extraction_gcn.py
â”œâ”€â”€ ghac/
â”‚   â””â”€â”€ ghac.py
â”œâ”€â”€ het_network/
â”‚   â””â”€â”€ network_creation.py
â”œâ”€â”€ nlp/
â”‚   â””â”€â”€ nlp.py
â”œâ”€â”€ gui.py                       # Main GUI script
â””â”€â”€ README.md
```

## Modules Overview

- **Pre-processing**: Filters input JSONs by selected features.
- **NLP**: Extracts contextual embeddings using SciBERT (`allenai/scibert_scivocab_uncased`).
- **Graph Construction**: Builds a heterogeneous graph including papers, authors, abstracts, venues, and keywords.
- **GCN**: Learns refined node embeddings from the graph structure.
- **GHAC**: Clusters documents into authors and evaluates results using standard AND metrics.

## Dependencies and Installation

We recommend using **Python 3.10+**. To install dependencies:

- PyTorch
- PyTorch Geometric
- HuggingFace Transformers
- scikit-learn
- ttkbootstrap
- tqdm
- pandas
- networkx


```bash
git clone https://anonymous.4open.science/r/ComMAND-CD68.git
cd ComMAND
pip install -r requirements.txt
```


## Running the Application


To start the GUI:

```bash
python gui.py
```

The interface supports:
- Feature selection
- Pre-processing
- Embedding extraction
- Graph construction
- GCN training
- GHAC clustering and evaluation


The framework is compatible with standard AND datasets, including:
- **AMiner-12**
- **AMiner-18**
- **DBLP**

Sample datasets are provided in compressed format inside the `datasets/` directory for testing purposes.


The `datasets/` directory should contain structured JSON files with fields like:
```json
{
  "id": "doc1",
  "title": "...",
  "abstract": "...",
  "venue": "...",
  "coauthors": ["..."],
  "keywords": ["..."],
  "label": "real_author_id"
}
```


## Notes

- Evaluation includes Pairwise Precision, Recall, F1-score, ACP, AAP, and K-Metric.
